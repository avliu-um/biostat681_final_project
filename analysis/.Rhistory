sigma_1_sq = rinvgamma(n = 1, shape = a_1 + p / 2, scale = b_1 + sum(beta_1^2) / 2)
sigma_0_sq = rinvgamma(n = 1, shape = a_0 + p / 2, scale = b_0 + sum(beta_0^2) / 2)
# impute missing data
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
# store parameters
tau_p_samples[s] = mean(y_1_complete) - mean(y_0_complete)
sigma_samples[s, ] = c(sigma_0_sq, sigma_1_sq)
beta_1_samples[s, ] = beta_1
beta_0_samples[s, ] = beta_0
}
close(pb)
return(list(tau_p_samples = tau_p_samples,
sigma_samples = sigma_samples,
beta_1_samples = beta_1_samples,
beta_0_samples = beta_0_samples))
}
blr = bayesian_causal_inference_logistic_regression(X, y, A,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000)
bayesian_causal_inference_logistic_regression = function(X, y, treatment_indicator,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000) {
control_indicator = (!treatment_indicator)
X = cbind(1, X)
Xt = t(X)
n = dim(X)[1]
p = dim(X)[2]
n_1 = sum(treatment_indicator)
n_0 = sum(control_indicator)
# initialization
sigma_1_sq = rinvgamma(n = 1, shape = a_1, scale = b_1)
sigma_0_sq = rinvgamma(n = 1, shape = a_0, scale = b_0)
beta_1 = rnorm(p, mean = 0, sd = sqrt(sigma_1_sq))
beta_0 = rnorm(p, mean = 0, sd = sqrt(sigma_0_sq))
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete = rep(0, n)
y_0_complete = rep(0, n)
y_1_complete[treatment_indicator] = y[treatment_indicator]
y_0_complete[control_indicator] = y[control_indicator]
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# setup
tau_p_samples = rep(0, total_steps)
sigma_samples = matrix(0, nrow = total_steps, ncol = 2)
beta_1_samples = matrix(0, nrow = total_steps, ncol = p)
beta_0_samples = matrix(0, nrow = total_steps, ncol = p)
# gibbs sampler
pb = txtProgressBar(style = 3)
for (s in 1:total_steps) {
kappa_1 = y_1_complete - 0.5
kappa_0 = y_0_complete - 0.5
Sigma_1 = Xt %*% diag(g_1) %*% X
diag(Sigma_1) = diag(Sigma_1) + 1 / sigma_1_sq
Sigma_1 = solve(Sigma_1)
mu_1 = Sigma_1 %*% Xt %*% kappa_1
Sigma_0 = Xt %*% diag(g_0) %*% X
diag(Sigma_0) = diag(Sigma_0) + 1 / sigma_0_sq
Sigma_0 = solve(Sigma_0)
mu_0 = Sigma_0 %*% Xt %*% kappa_0
# draw g
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# draw beta
beta_1 = t(rmvnorm(n = 1, mean = mu_1, sigma = Sigma_1))
beta_0 = t(rmvnorm(n = 1, mean = mu_0, sigma = Sigma_0))
# draw sigma
sigma_1_sq = rinvgamma(n = 1, shape = a_1 + p / 2, scale = b_1 + sum(beta_1^2) / 2)
sigma_0_sq = rinvgamma(n = 1, shape = a_0 + p / 2, scale = b_0 + sum(beta_0^2) / 2)
# impute missing data
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
# store parameters
tau_p_samples[s] = mean(y_1_complete) - mean(y_0_complete)
sigma_samples[s, ] = c(sigma_0_sq, sigma_1_sq)
beta_1_samples[s, ] = beta_1
beta_0_samples[s, ] = beta_0
setTxtProgressBar(pb, s / total_steps)
}
close(pb)
return(list(tau_p_samples = tau_p_samples,
sigma_samples = sigma_samples,
beta_1_samples = beta_1_samples,
beta_0_samples = beta_0_samples))
}
blr = bayesian_causal_inference_logistic_regression(X, y, A,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000)
blr$tau_p_samples
hist(blr$tau_p_samples[5001:1000])
table(blr$tau_p_samples)
blr$sigma_samples
blr$beta_0_samples
blr$beta_1_samples
mwan(y[A] - y[!A])
mean(y[A] - y[!A])
mean(y[A]) - mean(y[!A])
sum(A)
summary(lr)
table(blr$tau_p_samples)
bayesian_causal_inference_logistic_regression = function(X, y, treatment_indicator,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000) {
control_indicator = (!treatment_indicator)
X = cbind(1, X)
Xt = t(X)
n = dim(X)[1]
p = dim(X)[2]
n_1 = sum(treatment_indicator)
n_0 = sum(control_indicator)
# initialization
sigma_1_sq = rinvgamma(n = 1, shape = a_1, scale = b_1)
sigma_0_sq = rinvgamma(n = 1, shape = a_0, scale = b_0)
beta_1 = rnorm(p, mean = 0, sd = sqrt(sigma_1_sq))
beta_0 = rnorm(p, mean = 0, sd = sqrt(sigma_0_sq))
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete = rep(0, n)
y_0_complete = rep(0, n)
y_1_complete[treatment_indicator] = y[treatment_indicator]
y_0_complete[control_indicator] = y[control_indicator]
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# setup
tau_p_samples = rep(0, total_steps)
sigma_samples = matrix(0, nrow = total_steps, ncol = 2)
beta_1_samples = matrix(0, nrow = total_steps, ncol = p)
beta_0_samples = matrix(0, nrow = total_steps, ncol = p)
# gibbs sampler
pb = txtProgressBar(style = 3)
for (s in 1:total_steps) {
kappa_1 = y_1_complete - 0.5
kappa_0 = y_0_complete - 0.5
Sigma_1 = Xt %*% diag(g_1) %*% X
diag(Sigma_1) = diag(Sigma_1) + 1 / sigma_1_sq
Sigma_1 = solve(Sigma_1)
mu_1 = Sigma_1 %*% Xt %*% kappa_1
Sigma_0 = Xt %*% diag(g_0) %*% X
diag(Sigma_0) = diag(Sigma_0) + 1 / sigma_0_sq
Sigma_0 = solve(Sigma_0)
mu_0 = Sigma_0 %*% Xt %*% kappa_0
# draw g
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# draw beta
beta_1 = t(rmvnorm(n = 1, mean = mu_1, sigma = Sigma_1))
beta_0 = t(rmvnorm(n = 1, mean = mu_0, sigma = Sigma_0))
# draw sigma
sigma_1_sq = rinvgamma(n = 1, shape = a_1 + p / 2, scale = b_1 + sum(beta_1^2) / 2)
sigma_0_sq = rinvgamma(n = 1, shape = a_0 + p / 2, scale = b_0 + sum(beta_0^2) / 2)
# impute missing data
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
browser()
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
# store parameters
tau_p_samples[s] = mean(y_1_complete) - mean(y_0_complete)
sigma_samples[s, ] = c(sigma_0_sq, sigma_1_sq)
beta_1_samples[s, ] = beta_1
beta_0_samples[s, ] = beta_0
setTxtProgressBar(pb, s / total_steps)
}
close(pb)
return(list(tau_p_samples = tau_p_samples,
sigma_samples = sigma_samples,
beta_1_samples = beta_1_samples,
beta_0_samples = beta_0_samples))
}
blr = bayesian_causal_inference_logistic_regression(X, y, A,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000)
p_1
p_0
beta_1
beta_0
hist(p_0)
hist(p_1)
X
X[, "age_diff"]
X[, c("age_diff", "rating_diff")] = scale(X[, c("age_diff", "rating_diff")])
blr = bayesian_causal_inference_logistic_regression(X, y, A,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 1000)
hist(p_1)
hist(p_0)
bayesian_causal_inference_logistic_regression = function(X, y, treatment_indicator,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000) {
control_indicator = (!treatment_indicator)
X = cbind(1, X)
Xt = t(X)
n = dim(X)[1]
p = dim(X)[2]
n_1 = sum(treatment_indicator)
n_0 = sum(control_indicator)
# initialization
sigma_1_sq = rinvgamma(n = 1, shape = a_1, scale = b_1)
sigma_0_sq = rinvgamma(n = 1, shape = a_0, scale = b_0)
beta_1 = rnorm(p, mean = 0, sd = sqrt(sigma_1_sq))
beta_0 = rnorm(p, mean = 0, sd = sqrt(sigma_0_sq))
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete = rep(0, n)
y_0_complete = rep(0, n)
y_1_complete[treatment_indicator] = y[treatment_indicator]
y_0_complete[control_indicator] = y[control_indicator]
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# setup
tau_p_samples = rep(0, total_steps)
sigma_samples = matrix(0, nrow = total_steps, ncol = 2)
beta_1_samples = matrix(0, nrow = total_steps, ncol = p)
beta_0_samples = matrix(0, nrow = total_steps, ncol = p)
# gibbs sampler
pb = txtProgressBar(style = 3)
for (s in 1:total_steps) {
kappa_1 = y_1_complete - 0.5
kappa_0 = y_0_complete - 0.5
Sigma_1 = Xt %*% diag(g_1) %*% X
diag(Sigma_1) = diag(Sigma_1) + 1 / sigma_1_sq
Sigma_1 = solve(Sigma_1)
mu_1 = Sigma_1 %*% Xt %*% kappa_1
Sigma_0 = Xt %*% diag(g_0) %*% X
diag(Sigma_0) = diag(Sigma_0) + 1 / sigma_0_sq
Sigma_0 = solve(Sigma_0)
mu_0 = Sigma_0 %*% Xt %*% kappa_0
# draw g
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# draw beta
beta_1 = t(rmvnorm(n = 1, mean = mu_1, sigma = Sigma_1))
beta_0 = t(rmvnorm(n = 1, mean = mu_0, sigma = Sigma_0))
# draw sigma
sigma_1_sq = rinvgamma(n = 1, shape = a_1 + p / 2, scale = b_1 + sum(beta_1^2) / 2)
sigma_0_sq = rinvgamma(n = 1, shape = a_0 + p / 2, scale = b_0 + sum(beta_0^2) / 2)
# impute missing data
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
# store parameters
tau_p_samples[s] = mean(y_1_complete) - mean(y_0_complete)
sigma_samples[s, ] = c(sigma_0_sq, sigma_1_sq)
beta_1_samples[s, ] = beta_1
beta_0_samples[s, ] = beta_0
setTxtProgressBar(pb, s / total_steps)
}
close(pb)
return(list(tau_p_samples = tau_p_samples,
sigma_samples = sigma_samples,
beta_1_samples = beta_1_samples,
beta_0_samples = beta_0_samples))
}
blr = bayesian_causal_inference_logistic_regression(X, y, A,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 1000)
hist(blr$tau_p_samples[501:1000])
hist(blr$tau_p_samples[1:1000])
games = read.csv("games_200_22_clean.txt")
games = games[, -1]
games$medium = factor(games$medium)
games$time_control = relevel(factor(games$time_control), ref = "standard")
games$home_country_diff = relevel(factor(games$home_country_diff), ref = "0")
games$players_sex = relevel(factor(games$players_sex), ref = "MM")
cleaned_games = model.matrix(~ . - 1, data = games)
cleaned_games = cleaned_games[, -1]
cleaned_games = as.data.frame(cleaned_games)
lr = glm(upset ~ ., data = cleaned_games, family = binomial)
summary(lr)
A = cleaned_games$mediumonline
X = as.matrix(cleaned_games[, 2:10])
X[, c("age_diff", "rating_diff")] = scale(X[, c("age_diff", "rating_diff")])
y = cleaned_games$upset
set.seed(2022)
blr = bayesian_causal_inference_logistic_regression(X, y, A,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000)
hist(blr$tau_p_samples)
beta_0 = colMeans(blr$beta_0_samples)
beta_1 = colMeans(blr$beta_1_samples)
hist(cbind(1, X) %*% beta_0)
hist(1 / (1 + exp(-cbind(1, X) %*% beta_0)))
hist(1 / (1 + exp(-cbind(1, X) %*% beta_1)))
bayesian_causal_inference_logistic_regression = function(X, y, treatment_indicator,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000) {
control_indicator = (!treatment_indicator)
X = cbind(1, X)
Xt = t(X)
n = dim(X)[1]
p = dim(X)[2]
n_1 = sum(treatment_indicator)
n_0 = sum(control_indicator)
# initialization
# sigma_1_sq = rinvgamma(n = 1, shape = a_1, scale = b_1)
# sigma_0_sq = rinvgamma(n = 1, shape = a_0, scale = b_0)
# beta_1 = rnorm(p, mean = 0, sd = sqrt(sigma_1_sq))
# beta_0 = rnorm(p, mean = 0, sd = sqrt(sigma_0_sq))
# p_1 = 1 / (1 + exp(- X %*% beta_1))
# p_0 = 1 / (1 + exp(- X %*% beta_0))
sigma_1_sq = 1
sigma_0_sq = 1
beta_1 = rep(0, p)
beta_0 = rep(0, p)
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete = rep(0, n)
y_0_complete = rep(0, n)
y_1_complete[treatment_indicator] = y[treatment_indicator]
y_0_complete[control_indicator] = y[control_indicator]
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# setup
tau_p_samples = rep(0, total_steps)
sigma_samples = matrix(0, nrow = total_steps, ncol = 2)
beta_1_samples = matrix(0, nrow = total_steps, ncol = p)
beta_0_samples = matrix(0, nrow = total_steps, ncol = p)
# gibbs sampler
pb = txtProgressBar(style = 3)
for (s in 1:total_steps) {
kappa_1 = y_1_complete - 0.5
kappa_0 = y_0_complete - 0.5
Sigma_1 = Xt %*% diag(g_1) %*% X
diag(Sigma_1) = diag(Sigma_1) + 1 / sigma_1_sq
Sigma_1 = solve(Sigma_1)
mu_1 = Sigma_1 %*% Xt %*% kappa_1
Sigma_0 = Xt %*% diag(g_0) %*% X
diag(Sigma_0) = diag(Sigma_0) + 1 / sigma_0_sq
Sigma_0 = solve(Sigma_0)
mu_0 = Sigma_0 %*% Xt %*% kappa_0
# draw g
g_1 = draw_g(n, X %*% beta_1)
g_0 = draw_g(n, X %*% beta_0)
# draw beta
beta_1 = t(rmvnorm(n = 1, mean = mu_1, sigma = Sigma_1))
beta_0 = t(rmvnorm(n = 1, mean = mu_0, sigma = Sigma_0))
# draw sigma
sigma_1_sq = rinvgamma(n = 1, shape = a_1 + p / 2, scale = b_1 + sum(beta_1^2) / 2)
sigma_0_sq = rinvgamma(n = 1, shape = a_0 + p / 2, scale = b_0 + sum(beta_0^2) / 2)
# impute missing data
p_1 = 1 / (1 + exp(- X %*% beta_1))
p_0 = 1 / (1 + exp(- X %*% beta_0))
y_1_complete[control_indicator] = rbinom(n = n_0, size = 1, prob = p_1[control_indicator])
y_0_complete[treatment_indicator] = rbinom(n = n_1, size = 1, prob = p_0[treatment_indicator])
# store parameters
tau_p_samples[s] = mean(y_1_complete) - mean(y_0_complete)
sigma_samples[s, ] = c(sigma_0_sq, sigma_1_sq)
beta_1_samples[s, ] = beta_1
beta_0_samples[s, ] = beta_0
setTxtProgressBar(pb, s / total_steps)
}
close(pb)
return(list(tau_p_samples = tau_p_samples,
sigma_samples = sigma_samples,
beta_1_samples = beta_1_samples,
beta_0_samples = beta_0_samples))
}
set.seed(2022)
blr = bayesian_causal_inference_logistic_regression(X, y, A,
a_0 = 1, b_0 = 1, a_1 = 1, b_1 = 1,
total_steps = 10000)
hist(blr$tau_p_samples)
hist(blr$tau_p_samples[5001:1000])
beta_0 = colMeans(blr$beta_0_samples)
beta_1 = colMeans(blr$beta_1_samples)
hist(1 / (1 + exp(-cbind(1, X) %*% beta_0)))
hist(1 / (1 + exp(-cbind(1, X) %*% beta_1)))
n = length(A)
n
X
X = cbind(1, X)
n = length(A)
p = ncol(X)
treatment = which(A == 1)
control = which(A == 0)
n_1 = length(treatment)
n_0 = length(control)
set.seed(20220916)
a = 1
b = 1
y_1_complete = rep(0, n)
y_1_complete[treatment] = y[treatment]
y_0_complete = rep(0, n)
y_0_complete[control] = y[control]
beta_0 = rep(0, n)
beta_1 = rep(0, n)
sigma_0_sq = 1
sigma_1_sq = 1
y_1_complete[control] = rnorm(n_0, X[treatment, ] %*% beta_1, sqrt(sigma_1_sq))
y_0_complete[treatment] = rnorm(n_1, X[control, ] %*% beta_0, sqrt(sigma_0_sq))
inv_tXX = solve(t(X) %*% X)
tau_p_hat = rep(0, 10000)
# mcmc
for (s in 1:10000) {
mu_1 = inv_tXX %*% t(X) %*% y_1_complete
mu_0 = inv_tXX %*% t(X) %*% y_0_complete
s_1 = inv_tXX * sigma_1_sq
s_0 = inv_tXX * sigma_0_sq
rss_1 = sum((y_1_complete - X %*% beta_1)^2)
rss_0 = sum((y_0_complete - X %*% beta_0)^2)
beta_1 = t(rmvnorm(1, mu_1, s_1))
beta_0 = t(rmvnorm(1, mu_0, s_0))
sigma_1_sq = 1 / rgamma(1, a + n / 2, b + rss_1 / 2)
sigma_0_sq = 1 / rgamma(1, a + n / 2, b + rss_0 / 2)
y_1_complete[control] = rnorm(n_0, X[treatment, ] %*% beta_1, sqrt(sigma_1_sq))
y_0_complete[treatment] = rnorm(n_1, X[control, ] %*% beta_0, sqrt(sigma_0_sq))
tau_p_hat[s] = mean(y_1_complete) - mean(y_0_complete)
}
mean(tau_p_hat)
p
length(beta_0)
set.seed(20220916)
a = 1
b = 1
y_1_complete = rep(0, n)
y_1_complete[treatment] = y[treatment]
y_0_complete = rep(0, n)
y_0_complete[control] = y[control]
beta_0 = rep(0, p)
beta_1 = rep(0, p)
sigma_0_sq = 1
sigma_1_sq = 1
y_1_complete[control] = rnorm(n_0, X[treatment, ] %*% beta_1, sqrt(sigma_1_sq))
y_0_complete[treatment] = rnorm(n_1, X[control, ] %*% beta_0, sqrt(sigma_0_sq))
inv_tXX = solve(t(X) %*% X)
tau_p_hat = rep(0, 10000)
# mcmc
for (s in 1:10000) {
mu_1 = inv_tXX %*% t(X) %*% y_1_complete
mu_0 = inv_tXX %*% t(X) %*% y_0_complete
s_1 = inv_tXX * sigma_1_sq
s_0 = inv_tXX * sigma_0_sq
rss_1 = sum((y_1_complete - X %*% beta_1)^2)
rss_0 = sum((y_0_complete - X %*% beta_0)^2)
beta_1 = t(rmvnorm(1, mu_1, s_1))
beta_0 = t(rmvnorm(1, mu_0, s_0))
sigma_1_sq = 1 / rgamma(1, a + n / 2, b + rss_1 / 2)
sigma_0_sq = 1 / rgamma(1, a + n / 2, b + rss_0 / 2)
y_1_complete[control] = rnorm(n_0, X[treatment, ] %*% beta_1, sqrt(sigma_1_sq))
y_0_complete[treatment] = rnorm(n_1, X[control, ] %*% beta_0, sqrt(sigma_0_sq))
tau_p_hat[s] = mean(y_1_complete) - mean(y_0_complete)
}
mean(tau_p_hat)
quantile(tau_p_hat, c(0.025, 0.975))
hist(X %*% beta_0)
hist(X %*% beta_1)
hist(X %*% beta_0)
hist(X %*% beta_1)
hist(blr$tau_p_samples[5001:1000])
quantile(blr$tau_p_samples[5001:10000], c(0.025, 0.975))
A
set.seed(2022)
a = 1
b = 1
y_1_complete = rep(0, n)
y_1_complete[treatment] = y[treatment]
y_0_complete = rep(0, n)
y_0_complete[control] = y[control]
beta_0 = rep(0, p)
beta_1 = rep(0, p)
sigma_0_sq = 1
sigma_1_sq = 1
y_1_complete[control] = rnorm(n_0, X[treatment, ] %*% beta_1, sqrt(sigma_1_sq))
y_0_complete[treatment] = rnorm(n_1, X[control, ] %*% beta_0, sqrt(sigma_0_sq))
inv_tXX = solve(t(X) %*% X)
tau_p_hat = rep(0, 10000)
# mcmc
for (s in 1:10000) {
mu_1 = inv_tXX %*% t(X) %*% y_1_complete
mu_0 = inv_tXX %*% t(X) %*% y_0_complete
s_1 = inv_tXX * sigma_1_sq
s_0 = inv_tXX * sigma_0_sq
rss_1 = sum((y_1_complete - X %*% beta_1)^2)
rss_0 = sum((y_0_complete - X %*% beta_0)^2)
beta_1 = t(rmvnorm(1, mu_1, s_1))
beta_0 = t(rmvnorm(1, mu_0, s_0))
sigma_1_sq = 1 / rgamma(1, a + n / 2, b + rss_1 / 2)
sigma_0_sq = 1 / rgamma(1, a + n / 2, b + rss_0 / 2)
y_1_complete[control] = rnorm(n_0, X[treatment, ] %*% beta_1, sqrt(sigma_1_sq))
y_0_complete[treatment] = rnorm(n_1, X[control, ] %*% beta_0, sqrt(sigma_0_sq))
tau_p_hat[s] = mean(y_1_complete) - mean(y_0_complete)
}
mean(tau_p_hat)
quantile(tau_p_hat, c(0.025, 0.975))
setwd("~/Library/CloudStorage/OneDrive-Umich/Assignments/BIOSTAT 681/project/biostat681_final_project")
setwd("~/Library/CloudStorage/OneDrive-Umich/Assignments/BIOSTAT 681/project/biostat681_final_project/analysis")
###############################################################################
# Bayesian logistic regression
source("bayesian_logistic_regression_for_causal_inference.R")
games = read.csv("~/biostat681_final_project/games_200_22_clean.txt")
games = read.csv("~/biostat681_final_project/games_200_22_clean.csv")
games = read.csv("~biostat681_final_project/games_200_22_clean.csv")
games = read.csv("biostat681_final_project/games_200_22_clean.csv")
games = read.csv("games_200_22_clean.csv")
quantile(blr$tau_p_samples[5001:10000], c(0.025, 0.975))
quantile(tau_p_hat, c(0.025, 0.975))
mean(cleaned_games$upset[cleaned_games$mediumonline == 0])
mean(cleaned_games$upset[cleaned_games$mediumonline == 1])
